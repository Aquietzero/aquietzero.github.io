<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CAgbalumo:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"aquietzero.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"width":null},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":null,"activeClass":"disqus"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Efficiency is doing things right; effectiveness is doing the right things.  Two improvements will be made to the agents.  Use the \(\lambda\)-return for the policy evaluation requirements of the gene">
<meta property="og:type" content="article">
<meta property="og:title" content="Achieving goals more effectively and efficiently">
<meta property="og:url" content="https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/index.html">
<meta property="og:site_name" content="NullSpace">
<meta property="og:description" content="Efficiency is doing things right; effectiveness is doing the right things.  Two improvements will be made to the agents.  Use the \(\lambda\)-return for the policy evaluation requirements of the gene">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-09-21T16:00:00.000Z">
<meta property="article:modified_time" content="2025-04-19T07:11:29.528Z">
<meta property="article:author" content="bifnudo">
<meta property="article:tag" content="强化学习">
<meta property="article:tag" content="读书笔记">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/","path":"2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/","title":"Achieving goals more effectively and efficiently"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Achieving goals more effectively and efficiently | NullSpace</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BCZ3TL69CD"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-BCZ3TL69CD","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">NullSpace</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section">标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section">分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section">归档</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section">关于</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#learning-to-improve-policies-using-robust-targets"><span class="nav-number">1.</span> <span class="nav-text">Learning to
improve policies using robust targets</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sarsa%CE%BB-improving-policies-after-each-step-based-on-multi-step-estimates"><span class="nav-number">1.1.</span> <span class="nav-text">SARSA(λ):
Improving policies after each step based on multi-step estimates</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#watkins-q%CE%BB-decoupling-behavior-from-learning-again"><span class="nav-number">1.2.</span> <span class="nav-text">Watkin’s
Q(λ): Decoupling behavior from learning, again</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#agents-that-interact-learn-and-plan"><span class="nav-number">2.</span> <span class="nav-text">Agents that interact,
learn, and plan</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dyna-q-learning-sample-models"><span class="nav-number">2.1.</span> <span class="nav-text">Dyna-Q: Learning sample
models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#trajectory-sampling-making-plans-for-the-immediate-future"><span class="nav-number">2.2.</span> <span class="nav-text">Trajectory
sampling: Making plans for the immediate future</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="bifnudo"
      src="/assets/images/me.webp">
  <p class="site-author-name" itemprop="name">bifnudo</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">120</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/aquietzero" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;aquietzero" rel="noopener me" target="_blank">GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.douban.com/people/aquietzero" title="豆瓣 → https:&#x2F;&#x2F;www.douban.com&#x2F;people&#x2F;aquietzero" rel="noopener me" target="_blank">豆瓣</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhaoyunhaosss@gmail.com" title="E-Mail → mailto:zhaoyunhaosss@gmail.com" rel="noopener me" target="_blank">E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/assets/images/me.webp">
      <meta itemprop="name" content="bifnudo">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NullSpace">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Achieving goals more effectively and efficiently | NullSpace">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Achieving goals more effectively and efficiently
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-22 00:00:00" itemprop="dateCreated datePublished" datetime="2023-09-22T00:00:00+08:00">2023-09-22</time>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>602</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><blockquote>
<p><strong><em>Efficiency is doing things right; effectiveness is doing
the right things.</em></strong></p>
</blockquote>
<p>Two improvements will be made to the agents.</p>
<ol type="1">
<li>Use the <span class="math inline">\(\lambda\)</span>-return for the
policy evaluation requirements of the generalized policy iteration
pattern.</li>
<li>Explore algorithms that use experience samples to learn a model of
the environment, a Markov decision process (MDP). The group of
algorithms that attempt to learn a model of the environment is referred
to as <strong>model-based reinforcement learning</strong>.</li>
</ol>
<aside>
<p>💡 <strong>Planning</strong>: Refers to algorithms that require a
model of the environment to produce a policy.</p>
<p><strong>Model-free RL</strong>: Refers to algorithms that don’t use
models of the environment, but are still able to produce a policy. Such
as MC, SARSA, and Q-learning.</p>
<p><strong>Model-based RL</strong>: Refers to algorithms that can learn,
but don’t require, a model of the environment to produce a policy. The
distinction is they don’t require models in advance, but can certainly
make good use of them if available, and more importantly, attempt to
learn the models through interaction with the environment. Such as
Dyna-Q and trajectory sampling.</p>
</aside>
<h1 id="learning-to-improve-policies-using-robust-targets">Learning to
improve policies using robust targets</h1>
<h2
id="sarsaλ-improving-policies-after-each-step-based-on-multi-step-estimates">SARSA(<strong>λ</strong>):
Improving policies after each step based on multi-step estimates</h2>
<p>SARSA(<span class="math inline">\(\lambda\)</span>) is a
straightforward improvement to the original SARSA agent. The main
difference between SARSA and SARSA(<span
class="math inline">\(\lambda\)</span>) is that we use <span
class="math inline">\(\lambda\)</span>-return in SARSA(<span
class="math inline">\(\lambda\)</span>).</p>
<aside>
<p>💡 The name SARSA comes from the quintuple of events that the
algorithm uses: <span class="math inline">\((S_t, A_t, R_{t+1}, S_{t+1},
A_{t+1})\)</span></p>
</aside>
<p><img
src="/assets/images/2023-09-22-achieving-goals-more-effectively-and-efficiently/accumulating-traces.png" /></p>
<p>The accumulating trace combines a frequency and a recency heuristic.
Traces have a way for combining frequency (how often you try a
state-action pair) and recency (how long ago you tried a state-action
pair) heuristics implicitly encoded in the trace mechanism.</p>
<p><img
src="/assets/images/2023-09-22-achieving-goals-more-effectively-and-efficiently/replacing-traces.png" /></p>
<h2 id="watkins-qλ-decoupling-behavior-from-learning-again">Watkin’s
Q(<strong>λ</strong>): Decoupling behavior from learning, again</h2>
<p><span class="math inline">\(Q(\lambda)\)</span> is an extension of
Q-learning that uses the <span
class="math inline">\(\lambda\)</span>-return for policy-evaluation
requirements of the generalized policy-iteration pattern. The only
change we’re doing here is replacing the TD target for off-policy
control (the one that uses the max over the action in the next state)
with a <span class="math inline">\(\lambda\)</span>-return for
off-policy control.</p>
<h1 id="agents-that-interact-learn-and-plan">Agents that interact,
learn, and plan</h1>
<p>The advantage of model-free RL over planning methods is that the
former doesn’t require MDPs. SARSA, Q-learning algorithms are
model-based reinforcement learning methods, which don’t need a MDP in
advance, but can learn through interacting with environment.</p>
<aside>
<p>💡 <strong>Sampling models</strong>: Refers to modesl of the
environment that produce a single sample of how the environment will
transition given some probabilities.</p>
<p><strong>Distributional models</strong>: Refers to models of the
environment that produce the probability distribution of the transition
and reward fucntions.</p>
</aside>
<h2 id="dyna-q-learning-sample-models">Dyna-Q: Learning sample
models</h2>
<p>One of the most well-known architectures for unifying planning and
model-free methods is called <strong>Dyna-Q</strong>. Dyna-Q consists of
interleaving a model-free RL method, such as Q-learning, and a planning
method, similar to value iteration, using both experiences sampled from
the environment and experiences sampled from the learned model to
improve the action-value function.</p>
<p><img
src="/assets/images/2023-09-22-achieving-goals-more-effectively-and-efficiently/model-based.png" /></p>
<h2
id="trajectory-sampling-making-plans-for-the-immediate-future">Trajectory
sampling: Making plans for the immediate future</h2>
<p>While Dyna-Q samples the learned MDP uniformly at random,
<strong>trajectory sampling</strong> gathers trajectories, that is,
transitions and rewards that can be encountered in the immediate
future.</p>
<p>The traditional trajectory-sampling approach is to sample from an
initial state until reaching a terminal state using the on-policy
trajectory. But nothing is limited. Samples starting from the current
state can also be a choice. As long as it is sampling a trajectory, it
is called <strong>trajectory sampling</strong>.</p>

    </div>

    
    
    

    <footer class="post-footer">

<script>
  function resizeIframe() {
    const obj = document.querySelector('.post-body iframe');
    obj.onload = () => {
      obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';
      obj.setAttribute('scrolling', 'no');
    }
  }
  resizeIframe();
</script>
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>bifnudo
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/" title="Achieving goals more effectively and efficiently">https://aquietzero.github.io/2023/09/22/reading/grokking-deep-reinforcement-learning/2023-09-22-achieving-goals-more-effectively-and-efficiently/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag"># 强化学习</a>
              <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag"># 读书笔记</a>
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/20/reading/grokking-deep-reinforcement-learning/2023-09-20-improving-agents-behaviors/" rel="prev" title="Improving Agent's Behaviors">
                  <i class="fa fa-angle-left"></i> Improving Agent's Behaviors
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/09/25/reading/grokking-deep-reinforcement-learning/2023-09-25-more-stable-value-based-methods/" rel="next" title="More stable value-based methods">
                  More stable value-based methods <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">bifnudo</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">290k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">17:34</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/aquietzero" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"version":"11.5.0","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.5.0/mermaid.min.js","integrity":"sha256-K7oJiQlDulzl24ZUFOywuYme1JqBBvQzK6m8qHjt9Gk="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"aquietzero-github-io","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
